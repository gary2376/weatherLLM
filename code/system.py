import openai
try:
    from openai import OpenAI
    HAS_OPENAI_NEW = True
except Exception:
    OpenAI = None
    HAS_OPENAI_NEW = False
import os
import sqlite3
import json
from datetime import datetime, timezone, timedelta
from typing import Optional
import time

import pandas as pd  # è®€å– Excel ç”¨
import requests
import glob
import xml.etree.ElementTree as ET
from pathlib import Path
import sys

# Standardized prefixes to avoid emoji/encoding issues on some consoles
ERROR_PREFIX = "ERROR:"
WARN_PREFIX = "WARN:"

def _make_safe(msg: str) -> str:
    """Return a console-safe representation of msg.

    If the current stdout encoding supports UTF-8, return the original message so
    human-readable Chinese/emoji are preserved. Otherwise, fallback to escaping
    non-ASCII characters (backslashreplace) to avoid encoding errors in environments
    using latin-1 or other limited encodings.
    """
    try:
        enc = None
        if hasattr(sys, 'stdout') and getattr(sys, 'stdout') is not None:
            enc = getattr(sys.stdout, 'encoding', None)
        if not enc:
            enc = os.environ.get('PYTHONIOENCODING')
        # If the current encoding can encode the message, return it unchanged
        if enc:
            try:
                msg.encode(enc)
                return msg
            except Exception:
                pass
        # fallback: escape non-ascii into \uXXXX so it is safe for limited consoles
        return msg.encode('ascii', 'backslashreplace').decode('ascii')
    except Exception:
        # last resort: explicit \uXXXX replacement
        return ''.join(c if ord(c) < 128 else f'\\u{ord(c):04x}' for c in msg)

# è«‹å‹¿å°‡ OpenAI API Key ç¡¬ç·¨ç¢¼åœ¨ç¨‹å¼ç¢¼ä¸­ã€‚
# é‡‘é‘°æ‡‰ç”±åŸ·è¡Œç’°å¢ƒæˆ–å‘¼å«ç«¯è¨­å®šï¼Œä¾‹å¦‚ï¼š
#  - ä½¿ç”¨ç’°å¢ƒè®Šæ•¸ OPENAI_API_KEY
#  - æˆ–ç”±å‘¼å«çš„æ‡‰ç”¨ç¨‹å¼ï¼ˆä¾‹å¦‚ streamlitï¼‰å‹•æ…‹è¨­å®š system.openai.api_key
env_openai_key = os.getenv("OPENAI_API_KEY")
if env_openai_key:
    openai.api_key = env_openai_key

# æ˜¯å¦ä½¿ç”¨æœ¬æ©Ÿè³‡æ–™ï¼ˆDB / radar XML / Excelï¼‰ã€‚é è¨­ä½¿ç”¨æœ¬æ©Ÿè³‡æ–™ï¼Œä½†åœ¨è¦ä¸Šå‚³åˆ° GitHub
# æˆ–åŸ·è¡Œæ–¼ä¸èƒ½ä¾è³´æœ¬æ©Ÿæª”æ¡ˆçš„ç’°å¢ƒæ™‚ï¼Œå¯è¨­å®šç’°å¢ƒè®Šæ•¸ USE_LOCAL_DATA=0
USE_LOCAL_DATA = os.getenv("USE_LOCAL_DATA", "1") != "0"

# SQLite è³‡æ–™åº«è·¯å¾‘
DATABASE_NAME = r"E:\python_project\contest\TGIS\DB\taichung_weather.db"

# è‡ªè¨‚å€åŸŸ ID â†” å€åŸŸåç¨± å°æ‡‰è¡¨
CUSTOM_ID_TO_NAME_MAP = {
    1: "ä¸­å€", 2: "åŒ—å€", 3: "åŒ—å±¯å€", 4: "å—å€", 5: "å—å±¯å€",
    6: "åé‡Œå€", 7: "å’Œå¹³å€", 8: "å¤–åŸ”å€", 9: "å¤§å®‰å€", 10: "å¤§ç”²å€",
    11: "å¤§è‚šå€", 12: "å¤§é‡Œå€", 13: "å¤§é›…å€", 14: "å¤ªå¹³å€", 15: "æ–°ç¤¾å€",
    16: "æ±å‹¢å€", 17: "æ±å€", 18: "æ¢§æ£²å€", 19: "æ²™é¹¿å€", 20: "æ¸…æ°´å€",
    21: "æ½­å­å€", 22: "çƒæ—¥å€", 23: "çŸ³å²¡å€", 24: "ç¥å²¡å€", 25: "è¥¿å€",
    26: "è¥¿å±¯å€", 27: "è±åŸå€", 28: "éœ§å³°å€", 29: "é¾äº•å€"
}
NAME_TO_CUSTOM_ID_MAP = {v: k for k, v in CUSTOM_ID_TO_NAME_MAP.items()}

# å¯æ“´å……çš„è¡Œæ”¿å€ -> ç¶“ç·¯åº¦æ˜ å°„ï¼ˆè‹¥ç„¡æ›´ç²¾æº–åº§æ¨™ï¼Œæœƒä½¿ç”¨å°ä¸­å¸‚ä¸­å¿ƒä½œç‚ºé è¨­ï¼‰
# æ³¨æ„ï¼šéƒ¨åˆ†åº§æ¨™ç‚ºæš«æ™‚é è¨­ï¼ˆä½¿ç”¨å°ä¸­å¸‚ä¸­å¿ƒï¼‰ï¼Œè‹¥éœ€è¦æ›´ç²¾æº–ä½ç½®å»ºè­°ä»¥å®˜æ–¹æˆ–åœ°ç†ç·¨ç¢¼è³‡æ–™æ›´æ–°ã€‚
TAICHUNG_CENTER = (24.1477, 120.6736)
AREA_COORDS: dict[str, tuple[float, float]] = {
    "å°ä¸­å¸‚": TAICHUNG_CENTER,
    "è‡ºä¸­": TAICHUNG_CENTER,
    # å¸‚ä¸­å¿ƒæˆ–ä¸»è¦è¡Œæ”¿å€ï¼ˆè‹¥æœ‰æ›´ç²¾æº–ç¶“ç·¯åº¦ï¼Œå¯æ›¿æ›ä¸‹åˆ—å€¼ï¼‰
    "ä¸­å€": (24.14383, 120.67951),
    "åŒ—å€": (24.166039, 120.682318),
    "è¥¿å€": (24.14138, 120.67104),
    "æ±å€": (24.136625, 120.703854),
    "å—å€": (24.117079, 120.663608),
    "åŒ—å±¯å€": (24.182264, 120.686288),
    "è¥¿å±¯å€": (24.165303, 120.633655),
    "å—å±¯å€": (24.134631, 120.644374),
    "å¤ªå¹³å€": (24.126472, 120.718523),
    "å¤§é‡Œå€": (24.099417, 120.67786),
    "éœ§å³°å€": (24.061698, 120.700272),
    "è±åŸå€": (24.24219, 120.71846),
    "æ½­å­å€": (24.20953, 120.70516),
    "å¤§é›…å€": (24.229141, 120.64778),
    "å¤§ç”²å€": (24.34892, 120.62239),
    "å¤–åŸ”å€": (24.33201, 120.65437),
    "æ¸…æ°´å€": (24.268576, 120.559767),
    "æ¢§æ£²å€": (24.254924, 120.531626),
    "é¾äº•å€": (24.192679, 120.545838),
    "çƒæ—¥å€": (24.104696, 120.623806),
    "å¤§è‚šå€": (24.151083, 120.545439),
    "çŸ³å²¡å€": (24.27498, 120.78041),
    "åé‡Œå€": (24.30491, 120.71071),
    "æ–°ç¤¾å€": (24.23414, 120.8095),
    "æ±å‹¢å€": (24.25861, 120.82777),
    "å’Œå¹³å€": (24.17477, 120.88349),
    "ç¥å²¡å€": (24.257826, 120.661511),
    "æ²™é¹¿å€": (24.233445, 120.566218),
    "å¤§å®‰å€": (24.34607, 120.58652),
    # è‹¥æœ‰éœ€è¦ï¼Œå¯åœ¨æ­¤è™•åŠ å…¥æ›´å¤šåˆ¥åæˆ–æ›¿ä»£æ‹¼æ³•
}

# ========= ä¸€å•Ÿå‹•ç¨‹å¼å°±æŠŠ attractions.xlsx è®€é€²ä¾† =========
# ä½¿ç”¨æ•´åˆå¾Œçš„æ™¯é»æª”æ¡ˆï¼ˆèˆ‡ Streamlit app ç›¸åŒï¼‰
EXCEL_PATH = r"E:\python_project\contest\TGIS\Data\location_consolidated_enhanced.xlsx"
try:
    # sheet_name=None æœƒæŠŠæ¯å€‹ sheet è®€æˆ { "è¥¿å±¯å€": DataFrame, "åŒ—å€": DataFrame, ... }
    ATTRACTIONS_SHEETS: dict[str, pd.DataFrame] = pd.read_excel(
        EXCEL_PATH, sheet_name=None, engine="openpyxl"
    )
except Exception as e:
    # è®€ä¸åˆ° Excel ä¸æ‡‰è©²é˜»æ–·æ•´å€‹æ‡‰ç”¨ï¼Œæ”¹ç‚ºç©ºè³‡æ–™ä¸¦åœ¨æ—¥èªŒä¸­æé†’
    print(_make_safe(f"{WARN_PREFIX} ç„¡æ³•è®€å– Excel æª” {EXCEL_PATH}ï¼š{e} - å°‡ä½¿ç”¨ç©ºçš„æ™¯é»/ä½å®¿æ¸…å–®"))
    ATTRACTIONS_SHEETS = {}
# ======================================================

def analyze_prompt_with_llm(user_prompt: str) -> dict:
    """
    å‘¼å« LLM æŠŠä½¿ç”¨è€…å•é¡Œè§£ææˆ JSONï¼ŒåŒ…å«ï¼š
      - type: 'radar' æˆ– 'forecast'
      - area: è¡Œæ”¿å€åç¨± (e.g. 'è¥¿å±¯å€')
      - date: YYYY-MM-DD (è‹¥ type == 'forecast')
      - hour: HH:MM (å¯é¸ï¼Œå¦å‰‡é è¨­ç”¨ 06:00 æˆ– 18:00)
    """
    today_str = datetime.now().strftime("%Y-%m-%d")
    system_prompt = (
        f"ä»Šå¤©æ˜¯ {today_str}ã€‚\n"
        "ä½ æ˜¯ä¸€å€‹å¤©æ°£æŸ¥è©¢ç†è§£åŠ©æ‰‹ï¼Œè«‹å¾ä½¿ç”¨è€…çš„å•é¡Œä¸­æŠ½å–å‡ºä»¥ä¸‹è³‡è¨Šä¸¦ä»¥ JSON å›å‚³ï¼š\n\n"
        "- type: 'radar' æˆ– 'forecast'\n"
        "  - æŸ¥è©¢ã€ç¾åœ¨ã€å³æ™‚ã€ç­‰ä¸€ä¸‹ã€ç›®å‰ã€é€™æ™‚å€™ã€ç­‰å±¬æ–¼ radar\n"
        "  - æŸ¥è©¢ã€æ˜å¤©ã€å¾Œå¤©ã€é€±æœ«ã€æ™šä¸Šã€æ—©ä¸Šã€æœªä¾†å¹¾å¤©ã€6æœˆ3æ—¥ã€ç­‰å±¬æ–¼ forecast\n\n"
        "- area: å°ä¸­å¸‚çš„è¡Œæ”¿å€åç¨±ï¼Œå¦‚ 'è¥¿å±¯å€', 'åŒ—å€' ç­‰ï¼›è‹¥æåŠæ™¯é»ï¼Œè«‹æ¨è«–è©²æ™¯é»æ‰€å±¬çš„è¡Œæ”¿å€ã€‚\n"
        "- date: å¦‚æœ type æ˜¯ forecastï¼Œè«‹å›å‚³æŸ¥è©¢ç›®æ¨™æ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰\n"
        "- hour: å¦‚æœ‰æä¾›æ™‚é–“ï¼Œå›å‚³æ ¼å¼ç‚º 'HH:MM'ï¼Œå¦å‰‡å¯çœç•¥\n\n"
    "åƒ…å›å‚³ JSON çµæœï¼Œè«‹å‹¿åŠ å…¥è§£é‡‹æˆ–å¤šé¤˜æ–‡å­—ã€‚"
    )

    # å…¼å®¹èˆŠç‰ˆèˆ‡æ–°ç‰ˆ openai å¥—ä»¶ï¼Œçµ±ä¸€å‘¼å« helper
    def _create_chat_completion(model, messages, **kwargs):
        if HAS_OPENAI_NEW and OpenAI is not None:
            client = OpenAI()
            return client.chat.completions.create(model=model, messages=messages, **kwargs)
        else:
            # fallback to older openai package interface
            return openai.ChatCompletion.create(model=model, messages=messages, **kwargs)

    def _extract_content(resp):
        # å˜—è©¦å¤šç¨®å¯ç”¨çš„ä½ç½®ä¾†å–å¾—å›å‚³å…§å®¹
        try:
            return resp.choices[0].message.content
        except Exception:
            try:
                return resp.choices[0].message['content']
            except Exception:
                try:
                    return resp.choices[0].text
                except Exception:
                    raise RuntimeError('ç„¡æ³•å¾ LLM å›å‚³ä¸­æ“·å–å…§å®¹')

    response = _create_chat_completion(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        max_tokens=150,
        temperature=0.2
    )
    content = _extract_content(response)
    # å¦‚æœå›å‚³æœ‰ code fenceï¼ŒæŠŠ ``` æˆ– ```json å»æ‰
    if content.startswith("```"):
        content = content.strip("`").strip()
        if content.lower().startswith("json"):
            content = content[4:].strip()
    return json.loads(content)


def get_attractions_for_area(area: str, top_n: int = 5) -> list[str]:
    """
    å›å‚³è©²å€åŸŸ (area) å‰ top_n å Type == "attraction" çš„æ™¯é»åç¨±æ¸…å–®ã€‚
    å¦‚æœæ‰¾ä¸åˆ°è©²å€ sheet æˆ–æ²’æœ‰ Type/Name æ¬„ä½ï¼Œå›å‚³ç©º listã€‚
    """
    # ATTRACTIONS_SHEETS may be a dict of sheets (one-per-district) or a single consolidated sheet.
    df: Optional[pd.DataFrame] = ATTRACTIONS_SHEETS.get(area)
    if df is None:
        # If there's a single consolidated sheet (e.g., 'Sheet1'), use it and filter by source_district
        if isinstance(ATTRACTIONS_SHEETS, dict) and len(ATTRACTIONS_SHEETS) == 1:
            df = list(ATTRACTIONS_SHEETS.values())[0]
        else:
            return []

    if "Type" not in df.columns or "Name" not in df.columns:
        return []

    # å¦‚æœ DataFrame æœ‰ source_district æ¬„ä½ï¼Œå„ªå…ˆä»¥åŒ…å«æ¯”å° (contains) ä¾†ç¯©é¸è©²å€åŸŸ
    df_work = df.copy()
    if 'source_district' in df_work.columns and isinstance(area, str):
        norm_area = area.replace('å°', 'è‡º')
        # match either 'æ²™é¹¿' or 'æ²™é¹¿å€' etc.
        df_work = df_work[df_work['source_district'].astype(str).str.contains(norm_area, na=False, case=False)]

    # ç¯©å‡º Type = "attraction"
    df_attraction = df_work[df_work["Type"].astype(str).str.lower() == "attraction"].copy()
    if df_attraction.empty:
        return []

    # å¦‚æœæœ‰ Rating æ¬„ï¼Œå°±ä¾ Rating ç”±é«˜åˆ°ä½æ’åº
    if "Rating" in df_attraction.columns:
        try:
            df_attraction = df_attraction.sort_values("Rating", ascending=False)
        except Exception:
            pass

    # å›å‚³å‰ top_n å€‹ Name
    return df_attraction["Name"].head(top_n).astype(str).tolist()


def get_lodgings_for_area(area: str, top_n: int = 3) -> list[str]:
    """
    å›å‚³è©²å€åŸŸ (area) å‰ top_n å Type == "hotel" çš„ä½å®¿åç¨±æ¸…å–®ã€‚
    å¦‚æœæ‰¾ä¸åˆ°è©²å€ sheet æˆ–æ²’æœ‰ Type/Name æ¬„ä½ï¼Œå›å‚³ç©º listã€‚
    """
    df: Optional[pd.DataFrame] = ATTRACTIONS_SHEETS.get(area)
    if df is None:
        return []

    if "Type" not in df.columns or "Name" not in df.columns:
        return []

    # ç¯©å‡º Type = "hotel"
    df_hotel = df[df["Type"].astype(str).str.lower() == "hotel"].copy()
    if df_hotel.empty:
        return []

    # å¦‚æœæœ‰ Rating æ¬„ï¼Œå°±ä¾ Rating ç”±é«˜åˆ°ä½æ’åº
    if "Rating" in df_hotel.columns:
        try:
            df_hotel = df_hotel.sort_values("Rating", ascending=False)
        except Exception:
            pass

    # å›å‚³å‰ top_n å€‹ Name
    return df_hotel["Name"].head(top_n).astype(str).tolist()


def generate_answer_from_user_prompt_and_data(user_prompt: str, raw_data: str) -> str:
    """
    å‘¼å« LLMï¼ŒæŠŠã€Œä½¿ç”¨è€…æå•ã€ä»¥åŠæ‹¼å¥½çš„ raw_data (åŒ…å«å¤©æ°£ã€æ™¯é»ã€ä½å®¿)
    ä¸€ä½µå‚³çµ¦ LLMï¼Œè®“å®ƒå›è¦†ä¸€æ®µå£èªåŒ–ã€è‡ªç„¶çš„å»ºè­°ã€‚
    """
    system_prompt = (
        "ä½ æ˜¯ä¸€å€‹æ•´åˆã€Œå¤©æ°£ï¼‹æ—…éŠï¼ä½å®¿ã€çš„å»ºè­°åŠ©æ‰‹ï¼Œ"
        "æ ¹æ“šä½¿ç”¨è€…çš„å•é¡Œä»¥åŠä¸‹é¢æä¾›çš„ã€Œå¤©æ°£è³‡æ–™ã€å’Œã€Œæ™¯é»æ¸…å–®ã€ä»¥åŠã€Œä½å®¿æ¸…å–®ã€ï¼Œ"
        "è«‹ç”¨ç¹é«”ä¸­æ–‡ç”¢ç”Ÿä¸€æ®µè‡ªç„¶ã€å£èªåŒ–ã€å®¹æ˜“ç†è§£çš„å›ç­”ã€‚\n\n"
        "è«‹åŒæ™‚åšåˆ°ï¼š\n"
        "1. å¤©æ°£éƒ¨åˆ†ï¼šé‡é»æ”¾åœ¨ã€é«”æ„Ÿæè¿°ã€èˆ‡ã€å»ºè­°ã€ï¼ˆä¾‹å¦‚ï¼šæ˜¯å¦è¦å¸¶å‚˜ã€ç©¿è–„å¤–å¥—ï¼çŸ­è¢–ã€æ³¨æ„é˜²æ›¬ï¼é˜²é›¨ç­‰ï¼‰ã€‚\n"
        "2. æ—…éŠæ™¯é»éƒ¨åˆ†ï¼šå¾ã€Œæ™¯é»æ¸…å–®ã€ä¸­ï¼ŒæŒ‘å¹¾å€‹é©åˆç•¶å¤©çš„æˆ¶å¤–ï¼å®¤å…§æ™¯é»ï¼Œä¸¦èªªæ˜ç‚ºä½•é©åˆï¼ˆä¾‹å¦‚ï¼šä»Šå¤©å¤ªç†±ï¼Œå°±æ¨è–¦å®¤å…§æˆ–æœ‰é®é™½çš„æ™¯é»ï¼‰ã€‚\n"
        "3. ä½å®¿éƒ¨åˆ†ï¼šæ¨è–¦ã€Œä½å®¿æ¸…å–®ã€ä¸­çš„å¹¾å€‹å„ªè³ªä½å®¿ï¼Œä¸¦ç°¡å–®èªªæ˜ç‚ºä½•é©åˆï¼ˆä¾‹å¦‚ï¼šè‹¥æ˜¯å¸¶å°å­©ï¼Œé€™é–“æ°‘å®¿ç’°å¢ƒé©åˆï¼›è‹¥æƒ³çœ‹å¤œæ™¯ï¼Œé€™å®¶é£¯åº—åœ°é»ä¾¿åˆ©ï¼‰ã€‚\n"
        "4. æ•´é«”é¢¨æ ¼è¦è‡ªç„¶ã€åƒæœ‹å‹èŠå¤©ï¼Œä¸è¦åªç¾…åˆ—åˆ—è¡¨æˆ–ç´”æ•¸æ“šã€‚\n"
    )

    user_prompt_combined = (
        f"ä½¿ç”¨è€…æå•ï¼š{user_prompt}\n"
        f"æŸ¥è©¢çµæœå¦‚ä¸‹ï¼š\n{raw_data}\n"
        "è«‹æ ¹æ“šä¸Šè¿°å…§å®¹ï¼Œç”Ÿæˆä¸€æ®µè‡ªç„¶èªè¨€çš„å›ç­”ã€‚"
    )

    # ä½¿ç”¨èˆ‡ analyze_prompt_with_llm ç›¸åŒçš„å…¼å®¹ helper
    def _create_chat_completion(model, messages, **kwargs):
        if HAS_OPENAI_NEW and OpenAI is not None:
            client = OpenAI()
            return client.chat.completions.create(model=model, messages=messages, **kwargs)
        else:
            return openai.ChatCompletion.create(model=model, messages=messages, **kwargs)

    def _extract_content(resp):
        try:
            return resp.choices[0].message.content
        except Exception:
            try:
                return resp.choices[0].message['content']
            except Exception:
                try:
                    return resp.choices[0].text
                except Exception:
                    raise RuntimeError('ç„¡æ³•å¾ LLM å›å‚³ä¸­æ“·å–å…§å®¹')

    try:
        response = _create_chat_completion(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user",   "content": user_prompt_combined}
            ],
            temperature=0.5,
            max_tokens=1000
        )
        generated_summary = _extract_content(response).strip()
    except Exception as e:
        # è‹¥ LLM å‘¼å«å¤±æ•—ï¼ˆç„¡ API keyã€ç¶²è·¯æˆ–èªè­‰éŒ¯èª¤ï¼‰ï¼Œå›å‚³å‹å–„ä¸” ASCII-safe çš„éŒ¯èª¤è¨Šæ¯
        return _make_safe(f"{ERROR_PREFIX} LLM å‘¼å«å¤±æ•—ï¼š{e}")

    # æ¸…ç†ï¼šè‹¥ LLM å›å‚³çš„æ˜¯ JSON æˆ–é™£åˆ—ï¼ˆä¾‹å¦‚æ„å¤–å›å‚³ [] / [null, ...]ï¼‰ï¼Œå˜—è©¦å°‡å…¶è½‰æˆå¯è®€æ–‡å­—
    try:
        # ç§»é™¤ code fence
        if generated_summary.startswith("```"):
            generated_summary = generated_summary.strip("`").strip()
        parsed = None
        try:
            parsed = json.loads(generated_summary)
        except Exception:
            parsed = None

        if parsed is not None:
            def _extract_text_from_json(obj):
                if obj is None:
                    return ""
                if isinstance(obj, str):
                    return obj
                if isinstance(obj, list):
                    parts = [_extract_text_from_json(i) for i in obj]
                    return "\n".join([p for p in parts if p])
                if isinstance(obj, dict):
                    parts = [_extract_text_from_json(v) for v in obj.values()]
                    return "\n".join([p for p in parts if p])
                return str(obj)

            cleaned = _extract_text_from_json(parsed).strip()
            if cleaned:
                generated_summary = cleaned
            else:
                # ç„¡æ³•å¾ JSON ä¸­æŠ½å‡ºå¯è®€æ–‡å­—ï¼Œæ”¹å›å‹å–„çš„éŒ¯èª¤æç¤º
                generated_summary = "ï¼ˆOpenAI å›å‚³çš„å…§å®¹ç‚ºæ©Ÿå™¨æ ¼å¼ï¼ç©ºå€¼ï¼Œè«‹ç¨å€™é‡è©¦æˆ–æ›´æ›æŸ¥è©¢ï¼‰"
    except Exception:
        # è‹¥æ¸…ç†æµç¨‹æœ‰ä¾‹å¤–ï¼Œä»å›å‚³åŸå§‹æ–‡æœ¬ï¼Œé¿å…åæ‰å¯èƒ½çš„æœ‰æ•ˆå›è¦†
        pass

    # æœ€å¾Œä¸€å±¤é˜²è­·ï¼šå¦‚æœå›å‚³æ˜¯ç©ºå­—ä¸²æˆ–ä»çœ‹èµ·ä¾†åƒæ©Ÿå™¨æ ¼å¼ï¼ˆä¾‹å¦‚åªåŒ…å« [] æˆ–å¤§é‡ nullï¼‰ï¼Œ
    # å‰‡ç›´æ¥å›é€€ç‚ºå‹å–„è¨Šæ¯ï¼Œé¿å…æŠŠæ©Ÿå™¨æ ¼å¼å‚³å›åˆ°å‰ç«¯
    try:
        def _is_machine_like(s: str) -> bool:
            if s is None:
                return True
            if not isinstance(s, str):
                return True
            ss = s.strip()
            if not ss:
                return True
            low = ss.lower()
            # æ˜é¡¯ç´” JSON çµæ§‹ä½†å…§å®¹æ²’æœ‰å¯è®€æ–‡å­—
            if low in ('[]', '[ ]', '{}'):
                return True
            try:
                parsed = json.loads(ss)
                # å¦‚æœè§£æå¾Œæ˜¯ list/dictï¼Œæª¢æŸ¥æ˜¯å¦å¯ä»¥æŠ½å‡ºä»»ä½•éç©ºå­—ä¸²
                def has_useful(o):
                    if o is None:
                        return False
                    if isinstance(o, str):
                        return bool(o.strip())
                    if isinstance(o, (list, tuple)):
                        return any(has_useful(i) for i in o)
                    if isinstance(o, dict):
                        return any(has_useful(v) for v in o.values())
                    return True
                if isinstance(parsed, (list, dict)) and not has_useful(parsed):
                    return True
            except Exception:
                # è‹¥ä¸èƒ½è§£æä½†åŒ…å«å¤šå€‹ null/noneï¼Œè¦–ç‚ºæ©Ÿå™¨æ ¼å¼
                if low.count('null') >= 1 or low.count('none') >= 1:
                    # è‹¥å­—ä¸²å¾ˆçŸ­ä¸”å¤§éƒ¨åˆ†æ˜¯ null/bracketsï¼Œè¦–ç‚ºæ©Ÿå™¨æ ¼å¼
                    cleaned = low.replace('null', '').replace('none', '').replace('[', '').replace(']', '').replace('{', '').replace('}', '').strip()
                    if len(cleaned) < 10:
                        return True
            return False

        if _is_machine_like(generated_summary):
            generated_summary = "ï¼ˆOpenAI å›å‚³çš„å…§å®¹ç„¡æ³•è§£æç‚ºå¯è®€æ–‡å­—ï¼Œè«‹ç¨å€™é‡è©¦æˆ–èª¿æ•´æŸ¥è©¢ã€‚ï¼‰"
    except Exception:
        # è‹¥æª¢æŸ¥å¤±æ•—ï¼Œä¿ç•™åŸå§‹å›è¦†
        pass

    return generated_summary


def fetch_radar_data(district_id: int, limit: int = 5) -> str:
    """
    æŸ¥è©¢æŒ‡å®š district_id çš„å³æ™‚é›·é”å›æ³¢è³‡æ–™ï¼Œå–æœ€æ–° limit ç­†ï¼Œä¸¦å›å‚³æˆæ–‡å­—ã€‚
    """
    try:
        conn = sqlite3.connect(DATABASE_NAME)
        cursor = conn.cursor()
        cursor.execute(
            """
            SELECT timestamp_utc, dbz_value
            FROM realtime_observations
            WHERE custom_district_id = ?
            ORDER BY timestamp_utc DESC
            LIMIT ?
            """,
            (district_id, limit)
        )
        rows = cursor.fetchall()
        conn.close()

        if not rows:
            # è‹¥æœ¬æ©Ÿ DB ä¸­ç„¡å³æ™‚é›·é”è³‡æ–™ï¼Œæ”¹ç‚ºä½¿ç”¨é ç«¯é™æ°´é‡ä½œç‚ºæ›¿ä»£ (Open-Meteo)
            area_name = CUSTOM_ID_TO_NAME_MAP.get(district_id)
            return fetch_precipitation_open_meteo(area=area_name)

        result = f"ğŸ“¡ é›·é”å›æ³¢ - {CUSTOM_ID_TO_NAME_MAP[district_id]}ï¼š\n"
        for t, dbz in rows:
            result += f"  - æ™‚é–“: {t}, dBZ å€¼: {dbz if dbz is not None else 'N/A'}\n"
        return result

    except Exception as e:
        return _make_safe(f"{ERROR_PREFIX} é›·é”è³‡æ–™æŸ¥è©¢éŒ¯èª¤ï¼š{e}")


def get_latest_radar_summary(radar_dir: str = r"E:\python_project\contest\TGIS\radar") -> str:
    """
    è®€å–æœ¬åœ° radar/ ç›®éŒ„ï¼Œæ‰¾æœ€æ–°çš„ XML æª”ï¼Œå›å‚³ç°¡çŸ­æ‘˜è¦ï¼ˆæª”åã€ä¿®æ”¹æ™‚é–“ã€è‹¥èƒ½è§£æå‰‡å›å‚³æ ¹ç¯€é»è³‡è¨Šï¼‰ã€‚
    æ­¤å‡½å¼ä¸ä¾è³´é ç«¯ APIï¼Œé©åˆä½œç‚ºæœ¬æ©Ÿ RAG çš„ä¸€éƒ¨åˆ†ã€‚
    """
    # å¦‚æœç’°å¢ƒè¨­å®šé—œé–‰æœ¬æ©Ÿè³‡æ–™ï¼Œæˆ– radar ç›®éŒ„ä¸å­˜åœ¨ï¼æ‰¾ä¸åˆ°æª”æ¡ˆï¼Œæ”¹ç”¨é ç«¯å³æ™‚é™æ°´è³‡æ–™ä½œç‚ºæ›¿ä»£
    try:
        p = Path(radar_dir)
        if p.exists() and USE_LOCAL_DATA:
            xml_files = sorted(p.glob('*.xml'), key=lambda x: x.stat().st_mtime, reverse=True)
            if xml_files:
                newest = xml_files[0]
                mtime = datetime.fromtimestamp(newest.stat().st_mtime)
                summary = f"Radar æª”æ¡ˆ: {newest.name} (æœ€å¾Œä¿®æ”¹: {mtime.strftime('%Y-%m-%d %H:%M:%S')})"
                # å˜—è©¦è§£æ XML ä¸¦æŠ“å‡ºå°‘é‡å¯è®€è³‡è¨Šï¼ˆå¦‚æœå¯èƒ½ï¼‰
                try:
                    tree = ET.parse(newest)
                    root = tree.getroot()
                    attrs = []
                    for k, v in list(root.attrib.items())[:5]:
                        attrs.append(f"{k}={v}")
                    if attrs:
                        summary += " | root_attrs: " + ",".join(attrs)
                except Exception:
                    pass
                return summary

        # fallback: ä»¥ Open-Meteo çš„é™é›¨é‡è³‡æ–™ä½œç‚ºä»£æ›¿ï¼ˆä¸éœ€è¦ API keyï¼‰
        return fetch_precipitation_open_meteo()
    except Exception as e:
        return f"ï¼ˆè®€å– radar/é ç«¯é™æ°´æ‘˜è¦æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}ï¼‰"


def fetch_precipitation_open_meteo(area: Optional[str] = None, lat: Optional[float] = None, lon: Optional[float] = None) -> str:
    """
    ä½¿ç”¨ Open-Meteo å–å¾—æœ€è¿‘æ•¸å°æ™‚çš„é™é›¨é‡ï¼ˆä½œç‚º radar çš„æ›¿ä»£ï¼‰ï¼Œè‹¥æœ‰ area å¯ç”¨ AREA_COORDS
    å›å‚³ç°¡çŸ­æ–‡å­—æ‘˜è¦ã€‚
    """
    try:
        if area and area in AREA_COORDS:
            lat, lon = AREA_COORDS[area]
        if lat is None or lon is None:
            lat, lon = AREA_COORDS.get("å°ä¸­å¸‚", (24.1477, 120.6736))

        # å–å¾—æœ€è¿‘ 6 å°æ™‚çš„ hourly precipitation
        url = (
            f"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}"
            "&hourly=precipitation&timezone=Asia/Taipei"
        )
        resp = requests.get(url, timeout=8)
        resp.raise_for_status()
        data = resp.json()
        hourly = data.get("hourly", {})
        times = hourly.get("time", [])
        prec = hourly.get("precipitation", [])
        if not times or not prec:
            return "ï¼ˆç„¡æ³•å¾ Open-Meteo å–å¾—é™æ°´è³‡è¨Šï¼‰"

        # å–æœ€å¾Œ 6 ç­†ï¼ˆæˆ–å°‘æ–¼ 6 ç­†ï¼‰ä½œæ‘˜è¦
        last_n = min(6, len(times))
        summary = "Open-Meteo é™é›¨é‡æ‘˜è¦ï¼š\n"
        for t, pval in zip(times[-last_n:], prec[-last_n:]):
            summary += f"  - {t}: é™æ°´é‡ {pval} mm\n"
        return summary
    except Exception as e:
        return f"ï¼ˆå–å¾—é ç«¯é™æ°´è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}ï¼‰"


def fetch_current_weather_open_meteo(lat: float = 24.1477, lon: float = 120.6736, area: Optional[str] = None) -> str:
    """
    ä½¿ç”¨ Open-Meteo å…¬å…± API å–å¾—ç•¶å‰å¤©æ°£ï¼ˆfree, ç„¡éœ€ API keyï¼‰ã€‚
    å›å‚³ç°¡çŸ­æ–‡å­—æ‘˜è¦ï¼Œä¾¿æ–¼ä½œç‚º RAG çš„ä¸Šä¸‹æ–‡è¼¸å…¥çµ¦ LLMã€‚
    """
    try:
        # å¦‚æœæœ‰æä¾›å€åŸŸåç¨±ä¸”åœ¨ AREA_COORDS ä¸­ï¼Œä½¿ç”¨å…¶åº§æ¨™
        if area and area in AREA_COORDS:
            lat, lon = AREA_COORDS[area]
        url = (
            f"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}"
            "&current_weather=true&timezone=Asia/Taipei"
        )
        resp = requests.get(url, timeout=8)
        resp.raise_for_status()
        data = resp.json()
        cw = data.get('current_weather') or {}
        if not cw:
            return "ï¼ˆç„¡æ³•å–å¾— Open-Meteo çš„å³æ™‚å¤©æ°£ï¼‰"
        t = cw.get('temperature')
        ws = cw.get('windspeed')
        wc = cw.get('weathercode')
        time_str = cw.get('time')
        summary = f"å³æ™‚å¤©æ°£ (Open-Meteo) - æ™‚é–“: {time_str}, æ°£æº«: {t}Â°C, é¢¨é€Ÿ: {ws} m/s, weathercode: {wc}"
        return summary
    except Exception as e:
        return f"ï¼ˆå–å¾—å³æ™‚å¤©æ°£æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}ï¼‰"


def fetch_forecast_data(
    district_id: int,
    target_date: datetime,
    limit: int = 1,
    target_hour: Optional[str] = None
) -> str:
    """
    æŸ¥è©¢æŒ‡å®š district_id åœ¨ target_date (YYYY-MM-DD) çš„å¤©æ°£é å ±ï¼Œ
    è‹¥æä¾› target_hour (å¦‚ "06:00" æˆ– "18:00")ï¼Œå†ä¾å°æ™‚éæ¿¾ï¼Œæœ€å¾Œå›å‚³æ–‡å­—çµæœã€‚
    """
    try:
        # æŠŠ target_date è½‰æˆå…©å€‹ UTC é‚Šç•Œï¼ˆ00:00 åˆ°éš”å¤© 00:00ï¼‰
        start_utc = datetime(
            target_date.year, target_date.month, target_date.day, tzinfo=timezone.utc
        )
        end_utc = start_utc + timedelta(days=1)

        conn = sqlite3.connect(DATABASE_NAME)
        cursor = conn.cursor()

        sql = """
            SELECT *
            FROM weekly_forecasts
            WHERE custom_district_id = ?
              AND forecast_period_start_utc >= ?
              AND forecast_period_start_utc < ?
        """
        params = [
            district_id,
            start_utc.strftime('%Y-%m-%d %H:%M:%S'),
            end_utc.strftime('%Y-%m-%d %H:%M:%S')
        ]

        if target_hour:
            sql += " AND strftime('%H:%M', forecast_period_start_utc) = ?"
            params.append(target_hour)

        sql += " ORDER BY forecast_period_start_utc ASC LIMIT ?"
        params.append(limit)

        cursor.execute(sql, tuple(params))
        rows = cursor.fetchall()
        column_names = [desc[0] for desc in cursor.description]
        conn.close()

        if not rows:
            # è‹¥æœ¬æ©Ÿ DB ä¸­æ²’æœ‰è©²å€çš„é å ±è³‡æ–™ï¼Œç›´æ¥ä½¿ç”¨ Open-Meteo ä½œç‚ºå¾Œå‚™ï¼ˆä¸ç®¡ DB æª”æ¡ˆæ˜¯å¦å­˜åœ¨ï¼‰
            try:
                area_name = CUSTOM_ID_TO_NAME_MAP.get(district_id)
                lat, lon = AREA_COORDS.get(area_name, AREA_COORDS.get("å°ä¸­å¸‚"))
                return fetch_forecast_open_meteo(lat, lon, target_date, target_hour)
            except Exception:
                return _make_safe(
                    f"{WARN_PREFIX} æ²’æœ‰æŸ¥åˆ° {CUSTOM_ID_TO_NAME_MAP[district_id]} {target_hour or ''} çš„ "
                    f"{target_date.strftime('%mæœˆ%dæ—¥')} é å ±è³‡æ–™"
                )

        result = f"ğŸŒ¤ï¸ {CUSTOM_ID_TO_NAME_MAP[district_id]} {target_hour or ''} å¤©æ°£é å ±ï¼ˆ{target_date.strftime('%mæœˆ%dæ—¥')}ï¼‰ï¼š\n"
        for row in rows:
            result += "=============================\n"
            for col, val in zip(column_names, row):
                result += f"{col}: {val}\n"
        return result

    except Exception as e:
        return _make_safe(f"{ERROR_PREFIX} é å ±è³‡æ–™æŸ¥è©¢éŒ¯èª¤ï¼š{e}")


def fetch_forecast_open_meteo(lat: float, lon: float, target_date: datetime, target_hour: Optional[str] = None) -> str:
    """
    ä½¿ç”¨ Open-Meteo å–å¾—æŒ‡å®šæ—¥æœŸ (target_date) èˆ‡æ™‚æ®µ (target_hour) çš„é å ±ï¼Œå›å‚³ç°¡çŸ­æ–‡å­—ã€‚
    - lat, lon: åº§æ¨™
    - target_date: datetime with the date to query (UTC tz aware expected)
    - target_hour: "06:00" or "18:00" æ¨£å¼ï¼Œè‹¥ None å‰‡å›å‚³è©²æ—¥ summary
    """
    try:
        # Open-Meteo æ¥å£: å–å¾—ç•¶æ—¥ hourly èˆ‡ daily è³‡æ–™
        date_str = target_date.strftime("%Y-%m-%d")
        url = (
            f"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}"
            "&hourly=temperature_2m,precipitation,weathercode&windspeed_unit=ms&timezone=Asia/Taipei"
            f"&start_date={date_str}&end_date={date_str}"
        )
        resp = requests.get(url, timeout=10)
        resp.raise_for_status()
        data = resp.json()
        hourly = data.get('hourly', {})
        times = hourly.get('time', [])
        temps = hourly.get('temperature_2m', [])
        prec = hourly.get('precipitation', [])
        codes = hourly.get('weathercode', [])

        if not times:
            return f"ï¼ˆOpen-Meteo æœªå›å‚³ {date_str} çš„é å ±è³‡æ–™ï¼‰"

        result = f"ğŸŒ¤ï¸ Open-Meteo å¤©æ°£é å ±ï¼ˆ{date_str}ï¼‰:\n"
        if target_hour:
            # å˜—è©¦åŒ¹é…ç›®æ¨™å°æ™‚
            # target_hour ä¾‹å¦‚ '06:00'ï¼Œæˆ‘å€‘æ¯”å°æ™‚åˆ†
            matched = False
            for t, tmp, p, c in zip(times, temps, prec, codes):
                if t.endswith(target_hour):
                    result += f"  - {t}: æ°£æº« {tmp}Â°C, é™æ°´ {p} mm, weathercode {c}\n"
                    matched = True
                    break
            if not matched:
                # æ‰¾ä¸åˆ°ç²¾ç¢ºå°æ™‚æ™‚ï¼Œå–è©²æ—¥æ—©ä¸Š/æ™šé–“ä»£è¡¨å€¼
                result += "  ï¼ˆæ‰¾ä¸åˆ°ç²¾ç¢ºæ™‚æ®µè³‡æ–™ï¼Œè«‹æ”¹ä»¥å…¨å¤©æ‘˜è¦ç‚ºä¸»ï¼‰\n"
        # æä¾›ç°¡çŸ­å…¨å¤©æ‘˜è¦ï¼ˆå–æœ€å¤§/æœ€å°/ç¸½é™æ°´ï¼‰
        try:
            temps_f = [float(x) for x in temps]
            prec_f = [float(x) for x in prec]
            result += f"  ç•¶æ—¥æœ€é«˜ {max(temps_f):.1f}Â°C, æœ€ä½ {min(temps_f):.1f}Â°C, ç¸½é™æ°´ {sum(prec_f):.1f} mm\n"
        except Exception:
            pass
        return result
    except Exception as e:
        return f"ï¼ˆä½¿ç”¨ Open-Meteo å–å¾—é å ±æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}ï¼‰"


def get_weather_data(user_prompt: str, area_override: Optional[str] = None) -> str:
    """
    ä¸»è¦å…¥å£ï¼šæ ¹æ“šä½¿ç”¨è€…æå•ï¼ŒåŸ·è¡Œä»¥ä¸‹æ­¥é©Ÿï¼š
    1. analyze_prompt_with_llm è§£æå‡º type, area, date, hour
    2. ä¾ type æ±ºå®šå‘¼å« fetch_radar_data æˆ– fetch_forecast_data
    3. å¦‚æœæŸ¥åˆ°å¤©æ°£è³‡æ–™ï¼Œç¹¼çºŒæŠ“è©²å€åŸŸçš„æ™¯é»èˆ‡ä½å®¿æ¸…å–®
    4. æŠŠã€Œå¤©æ°£ï¼‹æ™¯é»ï¼‹ä½å®¿ã€çµ„æˆ raw_dataï¼Œå‘¼å« generate_answer_from_user_prompt_and_data
    5. å›å‚³ LLM çš„æœ€çµ‚å»ºè­° (ä¸åŒ…å« system.py è‡ªå·±çš„ CCTV åˆ—è¡¨)
    """
    try:
        info = analyze_prompt_with_llm(user_prompt)
    except Exception as e: # æ›´é€šç”¨çš„ Exception æ•æ‰
        return _make_safe(f"{ERROR_PREFIX} Prompt åˆ†æéšæ®µå‡ºéŒ¯ï¼š{e}") # è¿”å›éŒ¯èª¤ä¿¡æ¯

    query_type = info.get("type")
    area = info.get("area") # area æ˜¯ä¸­æ–‡å€åŸŸåç¨±, e.g., "è¥¿å±¯å€"
    # å¦‚æœå‘¼å«ç«¯æä¾›è¦†å¯«çš„è¡Œæ”¿å€ï¼Œä½¿ç”¨å®ƒ
    if area_override:
        area = area_override

    if not area:
        return _make_safe(f"{ERROR_PREFIX} ç„¡æ³•è¾¨è­˜æ‚¨æƒ³æŸ¥è©¢çš„å€åŸŸã€‚") # æ›´å‹å¥½çš„æç¤º

    district_id = NAME_TO_CUSTOM_ID_MAP.get(area)
    if not district_id:
        return _make_safe(f"{ERROR_PREFIX} ç³»çµ±ä¸­æ‰¾ä¸åˆ°å€åŸŸã€{area}ã€çš„å°æ‡‰ IDï¼Œè«‹ç¢ºèªæ˜¯å¦ç‚ºå°ä¸­å¸‚çš„è¡Œæ”¿å€ã€‚") # æ›´å‹å¥½çš„æç¤º

    raw_data = "" # åˆå§‹åŒ– raw_data
    if query_type == "radar":
        raw_data = fetch_radar_data(district_id)
    elif query_type == "forecast":
        date_str = info.get("date")
        hour = info.get("hour", "06:00") # LLM çµ¦çš„ hour

        if not date_str:
            return _make_safe(f"{ERROR_PREFIX} é å ±æŸ¥è©¢éœ€è¦æœ‰æ•ˆæ—¥æœŸã€‚") # æ›´å‹å¥½çš„æç¤º

        try:
            target_date = datetime.strptime(date_str, "%Y-%m-%d").replace(tzinfo=timezone.utc)
        except ValueError:
            return _make_safe(f"{ERROR_PREFIX} æ—¥æœŸæ ¼å¼éŒ¯èª¤ ({date_str})ï¼Œæ‡‰ç‚º YYYY-MM-DDã€‚") # æ›´å‹å¥½çš„æç¤º

        # å¦‚æœ LLM å›å‚³çš„ hour ä¸æ˜¯ 06:00 æˆ– 18:00ï¼Œåšåˆç†çš„æ™‚æ®µè½‰æ›
        if hour and isinstance(hour, str) and hour not in ["06:00", "18:00"]: # æª¢æŸ¥ hour æ˜¯å¦æœ‰æ•ˆ
            try:
                hour_parts = hour.split(":")
                hour_int = int(hour_parts[0])
                if 0 <= hour_int <= 2:
                    target_date = target_date - timedelta(days=1)
                    hour = "18:00"
                elif 3 <= hour_int < 17:
                    hour = "06:00"
                else:
                    hour = "18:00"
            except Exception: # è‹¥è½‰æ›å¤±æ•—ï¼Œä½¿ç”¨é è¨­
                hour = "06:00"
        elif not hour: # å¦‚æœ hour æ˜¯ None æˆ–ç©ºå­—ä¸²
             hour = "06:00"


        raw_data = fetch_forecast_data(
            district_id,
            target_date=target_date,
            target_hour=hour
        )
    else:
        return _make_safe(f"{ERROR_PREFIX} ç„¡æ³•è¾¨è­˜æŸ¥è©¢é¡å‹ (æ‡‰ç‚º 'radar' æˆ– 'forecast')ã€‚LLM å›æ‡‰ type: {query_type or 'æœªæä¾›'}") # æ›´å‹å¥½çš„æç¤º

    # 3. å¦‚æœ fetch å¤©æ°£æ™‚æœ‰éŒ¯èª¤ï¼Œç›´æ¥å›å‚³
    if raw_data.startswith((WARN_PREFIX, ERROR_PREFIX)):
        return raw_data

    # 3.5 å–å¾—å³æ™‚å¤–éƒ¨è³‡æ–™ (RAG)ï¼šlocal radar summary èˆ‡ Open-Meteo å³æ™‚å¤©æ°£
    # é€™äº›è³‡æ–™æœƒä½µå…¥ raw_data ä½œç‚º LLM çš„ä¸Šä¸‹æ–‡ï¼Œæå‡å›è¦†çš„å³æ™‚æ€§
    try:
        radar_summary = get_latest_radar_summary()
        raw_data = f"[RAG - æœ¬æ©Ÿé›·é”æ‘˜è¦]\n{radar_summary}\n\n" + raw_data
    except Exception:
        pass
    try:
        # å„ªå…ˆä»¥ area å–å¾—å³æ™‚å¤©æ°£åº§æ¨™ï¼ˆè‹¥ area åœ¨ AREA_COORDS ä¸­å‰‡ä½¿ç”¨å°æ‡‰ç¶“ç·¯åº¦ï¼‰
        current_weather_summary = fetch_current_weather_open_meteo(area=area)
        raw_data = f"[RAG - å³æ™‚å¤©æ°£]\n{current_weather_summary}\n\n" + raw_data
    except Exception:
        pass

    # 4. æŠ“å–æ™¯é»èˆ‡ä½å®¿æ¸…å–®ï¼Œä¸¦æ‹¼æ¥åˆ° raw_data
    attractions_list = get_attractions_for_area(area, top_n=5)
    if attractions_list:
        raw_data += "\n\nğŸï¸ æ­¤å€æ¨è–¦æ™¯é»ï¼š\n"
        for idx, name in enumerate(attractions_list, start=1):
            raw_data += f"  {idx}. {name}\n" # ä¿®æ­£ç¸®æ’
    else:
        raw_data += f"\n\nğŸï¸ æŠ±æ­‰ï¼Œç›®å‰æ²’æœ‰ã€Œ{area}ã€çš„æ™¯é»è³‡æ–™å¯ä¾›æ¨è–¦ã€‚\n"

    lodgings_list = get_lodgings_for_area(area, top_n=3)
    if lodgings_list:
        raw_data += "\n\nğŸ¨ æ­¤å€æ¨è–¦ä½å®¿ï¼š\n"
        for idx, name in enumerate(lodgings_list, start=1):
            raw_data += f"  {idx}. {name}\n" # ä¿®æ­£ç¸®æ’
    else:
        raw_data += f"\n\nğŸ¨ æŠ±æ­‰ï¼Œç›®å‰æ²’æœ‰ã€Œ{area}ã€çš„ä½å®¿è³‡æ–™å¯ä¾›æ¨è–¦ã€‚\n"

    # 5. ä¸€ä½µæŠŠã€Œå¤©æ°£ + æ™¯é» + ä½å®¿ã€é€çµ¦ LLM ç”Ÿæˆæœ€çµ‚å›è¦†
    start_time = time.time()
    generated_summary = generate_answer_from_user_prompt_and_data(user_prompt, raw_data)
    elapsed = time.time() - start_time
    
    # é€™è£¡åªå›å‚³ LLM çš„å»ºè­°ï¼Œä¸åŒ…å« system.py è‡ªèº«çš„ CCTV åˆ—è¡¨
    llm_response_with_header = f"å›æ‡‰å»ºè­°ï¼ˆå›æ‡‰è€—æ™‚ {elapsed:.2f} ç§’ï¼‰ï¼š\n{generated_summary}"
    # è¿”å›çµ¦å‘¼å«ç«¯æ™‚ï¼Œä½¿ç”¨ _make_safe ä»¥é¿å…åœ¨æŸäº›çµ‚ç«¯æˆ–æ—¥èªŒç³»çµ±ç™¼ç”Ÿç·¨ç¢¼éŒ¯èª¤
    return _make_safe(llm_response_with_header)

if __name__ == "__main__":
    print(_make_safe("å°ä¸­å¤©æ°£å°å¹«æ‰‹ï¼Œè¼¸å…¥ä½ æƒ³æŸ¥è©¢çš„å…§å®¹å§ï¼ˆè¼¸å…¥ exit é›¢é–‹ï¼‰\n"))
    while True:
        user_input = input("ğŸ‘‰ è«‹è¼¸å…¥å•é¡Œï¼š")
        if user_input.lower().strip() == "exit":
            print("ğŸ‘‹ å†è¦‹ï¼")
            break
        print(get_weather_data(user_input))
        print("-" * 60)
